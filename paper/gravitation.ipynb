{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import maxent\n",
    "from maxent.sbi_gravitation import GravitySimulator, sim_wrapper, get_observation_points\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from sbi.inference import infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up true parameters\n",
    "m1 = 100. # solar masses\n",
    "m2 = 50. # solar masses\n",
    "m3 = 75 # solar masses\n",
    "G = 1.90809e5 # solar radius / solar mass * (km/s)^2\n",
    "v0 = np.array([15.,-40.]) # km/s\n",
    "\n",
    "true_params = [m1, m2, m3, v0[0], v0[1]]\n",
    "\n",
    "# set prior means\n",
    "prior_means = [85., 40., 70., 12., -30.]\n",
    "prior_cov = np.eye(5) * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate true trajectory and apply some noise to it\n",
    "if os.path.exists('true_trajectory.txt'):\n",
    "    true_traj = np.genfromtxt('true_trajectory.txt')\n",
    "else:\n",
    "    sim = GravitySimulator(m1, m2, m3, v0, G, random_noise=False)\n",
    "    true_traj = sim.run()\n",
    "    np.savetxt('true_trajectory.txt', true_traj)\n",
    "\n",
    "if os.path.exists('noisy_trajectory.txt'):\n",
    "    traj=np.genfromtxt('noisy_trajectory.txt')\n",
    "else:\n",
    "    sim = GravitySimulator(m1, m2, m3, v0, G, random_noise=True)\n",
    "    traj = sim.run()\n",
    "    np.savetxt('noisy_trajectory.txt', traj)\n",
    "\n",
    "observed_points = get_observation_points(traj)\n",
    "observation_summary_stats = observed_points.flatten()\n",
    "sim.plot_traj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform SNL inference\n",
    "prior = MultivariateNormal(loc=torch.as_tensor(prior_means),\n",
    "                            covariance_matrix=torch.as_tensor(torch.eye(5)*50))\n",
    "\n",
    "posterior = infer(sim_wrapper, prior, method='SNLE', num_simulations=2048, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from SNL posterior\n",
    "samples = posterior.sample((2000,), x=observation_summary_stats)\n",
    "\n",
    "np.savetxt('wide_prior_samples.txt', np.array(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up restraints for maxent\n",
    "# restraint structure: [value, uncertainty, indices... ]\n",
    "restraints = []\n",
    "for i, point in enumerate(observed_points):\n",
    "    value1 = point[0]\n",
    "    value2 = point[1]\n",
    "    uncertainty = 25\n",
    "    index = 20 * i + 19 # based on how we slice in get_observation_points()\n",
    "    restraints.append([value1, uncertainty, index, 0])\n",
    "    restraints.append([value2, uncertainty, index, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up laplace restraints\n",
    "laplace_restraints = []\n",
    "\n",
    "for i in range(len(restraints)):\n",
    "    traj_index = tuple(restraints[i][2:])\n",
    "    value = restraints[i][0]\n",
    "    uncertainty = restraints[i][1]\n",
    "    #p = maxentep.Laplace(uncertainty)\n",
    "    p = maxent.EmptyPrior()\n",
    "    r = maxent.Restraint(lambda traj, i=traj_index: traj[i], value, p)\n",
    "    laplace_restraints.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from prior for maxent\n",
    "np.random.seed(12656)\n",
    "prior_dist = np.random.multivariate_normal(prior_means, prior_cov, size=2048)\n",
    "np.save('maxent_prior_samples.npy', prior_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate trajectories for maxent from prior samples\n",
    "trajs = np.zeros([prior_dist.shape[0], 100, 2])\n",
    "\n",
    "for i, sample in enumerate(tqdm(prior_dist)):\n",
    "    m1, m2, m3, v0 = sample[0], sample[1], sample[2], sample[3:]\n",
    "    sim = GravitySimulator(m1, m2, m3, v0, random_noise=False)\n",
    "    traj = sim.run()\n",
    "    trajs[i] = traj\n",
    "    \n",
    "np.save('maxent_raw_trajectories.npy', trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run maxent on trajectories\n",
    "batch_size = prior_dist.shape[0]\n",
    "\n",
    "model = maxentep.MaxentModel(laplace_restraints)\n",
    "model.compile(tf.keras.optimizers.Adam(1e-4), 'mean_squared_error')\n",
    "# short burn-in\n",
    "h = model.fit(trajs, batch_size=batch_size, epochs=5000, verbose=1)\n",
    "# restart to reset learning rate\n",
    "h = model.fit(trajs, batch_size=batch_size, epochs=25000, verbose=1)\n",
    "\n",
    "np.savetxt('maxent_loss.txt', h.history['loss'])\n",
    "\n",
    "weights = model.traj_weights\n",
    "np.savetxt('maxent_traj_weights.txt', weights)\n",
    "\n",
    "avg_traj = np.sum(trajs * model.traj_weights[:, np.newaxis, np.newaxis], axis=0)\n",
    "np.savetxt('maxent_avg_traj.txt', avg_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Plotting code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
